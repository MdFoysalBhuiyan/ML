{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNks3s9cQ21gG821UScyrO7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MdFoysalBhuiyan/ML/blob/main/Ml%20paper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbxnYIANQRuO",
        "outputId": "fe8b5aa9-180b-4696-87a1-62b70f17a0c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [05:39:40] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Classification Report (with Polynomial Features):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.55      0.57       124\n",
            "           1       0.56      0.60      0.58       116\n",
            "\n",
            "    accuracy                           0.57       240\n",
            "   macro avg       0.58      0.58      0.57       240\n",
            "weighted avg       0.58      0.57      0.57       240\n",
            "\n",
            "XGBoost Accuracy (with Polynomial Features): 0.5750\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/fatigue_intervention_data.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Step 1: Prepare the features and target variable\n",
        "X = data.drop(columns=['fatigue_status'])  # Features (excluding the target variable)\n",
        "y = data['fatigue_status']  # Target variable (0: pre-fatigue, 1: post-fatigue)\n",
        "\n",
        "# Step 2: Apply Polynomial Features (degree 2) to capture non-linearities\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False) # include_bias=False to avoid a constant column\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Convert the polynomial features back to a DataFrame for easier handling and inspection (optional, but good for understanding)\n",
        "X_poly_df = pd.DataFrame(X_poly, columns=poly.get_feature_names_out(X.columns))\n",
        "\n",
        "# Step 3: Preprocess the data (standardization) on the new polynomial features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_poly_df)\n",
        "\n",
        "# Step 4: Feature Selection using PCA (Optional)\n",
        "# Reduce to a reasonable number of principal components. The number of features has increased significantly.\n",
        "# We'll start with 6 components, but this might be adjusted based on explained variance.\n",
        "pca = PCA(n_components=6)  # Adjust n_components as needed after inspecting explained variance ratio\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Step 5: Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 6: Model 1 - XGBoost Classifier\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "\n",
        "# Step 7: Evaluate the XGBoost model\n",
        "print(\"XGBoost Classification Report (with Polynomial Features):\")\n",
        "print(classification_report(y_test, xgb_predictions))\n",
        "\n",
        "# Step 8: Accuracy Score\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_predictions)\n",
        "print(f\"XGBoost Accuracy (with Polynomial Features): {xgb_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e44a4075"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83a70195",
        "outputId": "ae3cf1ac-64d7-42c5-a42e-c66436c80c2f"
      },
      "source": [
        "# Define the parameter distribution for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],  # Number of trees in the forest\n",
        "    'max_features': ['sqrt', 'log2'],           # Number of features to consider when looking for the best split\n",
        "    'max_depth': [10, 20, 30, 40, 50, None],     # Maximum number of levels in a tree\n",
        "    'min_samples_split': [2, 5, 10],            # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4],              # Minimum number of samples required to be at a leaf node\n",
        "    'bootstrap': [True, False]                  # Method of selecting samples for training each tree\n",
        "}\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "# n_iter: Number of parameter settings that are sampled. Trades off computational cost with quality of the solution.\n",
        "# cv: Number of folds for cross-validation\n",
        "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist,\n",
        "                                   n_iter=50, cv=5, verbose=2, random_state=42, n_jobs=-1, scoring='accuracy')\n",
        "\n",
        "# Fit RandomizedSearchCV to the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best parameters found: \", random_search.best_params_)\n",
        "\n",
        "# Get the best estimator\n",
        "best_rf_model = random_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best parameters found:  {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e543d864",
        "outputId": "0e4357ea-da88-45f3-ed39-ce9a33b82316"
      },
      "source": [
        "# Make predictions with the best Random Forest model\n",
        "rf_predictions = best_rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the best Random Forest model\n",
        "print(\"Random Forest Classification Report (Tuned):\")\n",
        "print(classification_report(y_test, rf_predictions))\n",
        "\n",
        "# Accuracy Score\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "print(f\"Random Forest Accuracy (Tuned): {rf_accuracy:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classification Report (Tuned):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.58      0.59       124\n",
            "           1       0.56      0.57      0.56       116\n",
            "\n",
            "    accuracy                           0.57       240\n",
            "   macro avg       0.57      0.57      0.57       240\n",
            "weighted avg       0.58      0.57      0.58       240\n",
            "\n",
            "Random Forest Accuracy (Tuned): 0.5750\n"
          ]
        }
      ]
    }
  ]
}